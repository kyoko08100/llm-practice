{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "username = os.getenv(\"USER_NAME\")\n",
    "assistant = os.getenv(\"ASSISTANT_NAME\")\n",
    "\n",
    "friend_messages = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    with open(f\"json/{assistant}_page_{i}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        for j, m in enumerate(data):\n",
    "            if m.get(\"author\").get(\"global_name\") == assistant and \"content\" in m:\n",
    "                friend_messages.append({\n",
    "                    \"text\": m[\"content\"],\n",
    "                    \"timestamp\": m[\"timestamp\"]\n",
    "                })\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# æ¸¬è©¦ç”¨æ ¼å­\n",
    "for d in friend_messages:\n",
    "    print(d)"
   ],
   "id": "67856d54689e8224",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### è™•ç†æ²’ç”¨çš„è¨Šæ¯",
   "id": "57184d1e44aac97f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def is_noise(text):\n",
    "    return (\n",
    "        len(text.strip()) < 2 or\n",
    "        text in [\"å“ˆå“ˆ\", \"å—¯\", \"OK\", \"å¥½\"]\n",
    "    )\n",
    "\n",
    "clean_messages = [\n",
    "    m for m in friend_messages\n",
    "    if not is_noise(m[\"text\"])\n",
    "]\n",
    "\n",
    "def normalize(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "for m in clean_messages:\n",
    "    m[\"text\"] = normalize(m[\"text\"])"
   ],
   "id": "1b74b0b5a834c4cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### åˆ‡chunk",
   "id": "dfafef14b12cf6d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_ts(ts_str):\n",
    "    return datetime.fromisoformat(ts_str)\n",
    "\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "last_ts = None\n",
    "\n",
    "MAX_GAP = timedelta(minutes=30)  # 30 åˆ†é˜\n",
    "\n",
    "for m in clean_messages:\n",
    "    ts = parse_ts(m[\"timestamp\"])\n",
    "\n",
    "    if (\n",
    "        last_ts is not None and\n",
    "        ts - last_ts > MAX_GAP and\n",
    "        len(current_chunk) >= 3\n",
    "    ):\n",
    "        chunks.append(current_chunk)\n",
    "        current_chunk = []\n",
    "\n",
    "    current_chunk.append(m[\"text\"])\n",
    "    last_ts = ts\n",
    "\n",
    "if len(current_chunk) >= 3:\n",
    "    chunks.append(current_chunk)\n"
   ],
   "id": "eb27e775018a27d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### è½‰æˆæ–‡å­—",
   "id": "3127ad73b3cf1a5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chunk_texts = [\n",
    "    \"\\n\".join(chunk)\n",
    "    for chunk in chunks\n",
    "]"
   ],
   "id": "cf1398689d4b3a37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### æœ€å° metadata",
   "id": "d8f9ac34ee70421c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "for chunk in chunk_texts:\n",
    "    documents.append({\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"chat_history\",\n",
    "            \"speaker\": \"friend\"\n",
    "        }\n",
    "    })"
   ],
   "id": "d7d61a8dc36911ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import random\n",
    "# print(len(chunks[0]))\n",
    "# for c in random.sample(chunks[0], 5):\n",
    "#     print(\"----\")\n",
    "#     print(\"\\n\".join(c))"
   ],
   "id": "9b4d3124da24990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### è½‰æˆ LangChain Document ä¸¦åŠ  metadata",
   "id": "a90cc8e2866e8ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_classic.schema import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    text = \"\\n\".join(chunk)  # chunk æœ¬èº«æ˜¯ list of messages\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\n",
    "            \"source\": \"chat_history\",\n",
    "            \"speaker\": \"friend\"\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "MAX_CHARS = 800  # ä¿å®ˆå€¼ï¼Œæœ¬åœ° embedding å¾ˆå®‰å…¨\n",
    "\n",
    "safe_documents = []\n",
    "\n",
    "for doc in documents:\n",
    "    text = doc.page_content\n",
    "    if len(text) <= MAX_CHARS:\n",
    "        safe_documents.append(doc)\n",
    "    else:\n",
    "        # å¼·åˆ¶åˆ‡å°æ®µ\n",
    "        for i in range(0, len(text), MAX_CHARS):\n",
    "            safe_documents.append(\n",
    "                Document(\n",
    "                    page_content=text[i:i+MAX_CHARS],\n",
    "                    metadata=doc.metadata\n",
    "                )\n",
    "            )\n",
    "\n"
   ],
   "id": "a5fcd2f7240b536d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### å»ºç«‹ Embedding ä¸¦å­˜å…¥ FAISS",
   "id": "712424717c684ad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# åˆå§‹åŒ– Embedding(ä½¿ç”¨ç·šä¸Šç‰ˆ)\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#     model=\"gemini-embedding-001\",\n",
    "#     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "# )\n",
    "\n",
    "# ä½¿ç”¨æœ¬åœ°ç«¯\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# å»ºç«‹å‘é‡è³‡æ–™åº«\n",
    "vectorstore = FAISS.from_documents(safe_documents, embeddings)\n",
    "\n",
    "# é¸æ“‡æ€§çš„ï¼šå­˜æª”ä»¥å¾Œå¯ä»¥è¼‰å…¥\n",
    "vectorstore.save_local(\"friend_faiss_index\")\n"
   ],
   "id": "b591eabb4546f49d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### å¾ FAISS å»ºç«‹ Retrieverï¼ˆæ–¹ä¾¿åš RAG æŸ¥è©¢ï¼‰",
   "id": "713b76b076caff29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}  # å–æœ€ç›¸ä¼¼ 5 å€‹ chunk\n",
    ")"
   ],
   "id": "8a39271af36e902f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### é€épromptè®“LLMæ¨¡ä»¿å›ç­”(å–®è¼ªå°è©±ã€‚ç„¡è¨˜æ†¶)",
   "id": "3db94ad868bb3ebc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_classic.chains import RetrievalQA\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "#\n",
    "# template = \"\"\"\n",
    "# ä½ æ­£åœ¨æ¨¡ä»¿æŸä½æœ‹å‹çš„èªªè©±æ–¹å¼å›ç­”å•é¡Œã€‚\n",
    "# ä»¥ä¸‹æ˜¯ä»–åœ¨é¡ä¼¼æƒ…å¢ƒä¸­çš„èŠå¤©ç´€éŒ„ï¼š\n",
    "# {context}\n",
    "#\n",
    "# è«‹ç”¨æœ‹å‹çš„èªæ°£å›ç­”ï¼Œä¸è¦ç›´æ¥å¼•ç”¨èŠå¤©ç´€éŒ„çš„æ–‡å­—ã€‚\n",
    "# \"\"\"\n",
    "#\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"context\", \"question\"],\n",
    "#     template=\"\"\"\n",
    "#         ä½ æ­£åœ¨æ¨¡ä»¿æŸä½çœŸå¯¦æœ‹å‹çš„èªªè©±æ–¹å¼ã€‚\n",
    "#         ä»¥ä¸‹æ˜¯ä»–åœ¨é¡ä¼¼æƒ…å¢ƒä¸­çš„èŠå¤©ç´€éŒ„ï¼š\n",
    "#         {context}\n",
    "#\n",
    "#         è¦å‰‡ï¼š\n",
    "#         - æ¨¡ä»¿èªæ°£èˆ‡ç”¨è©\n",
    "#         - ä¸è¦é€å­—å¼•ç”¨èŠå¤©ç´€éŒ„\n",
    "#         - ä¸ç¢ºå®šæ™‚è«‹ä¿å®ˆå›ç­”\n",
    "#\n",
    "#         å•é¡Œï¼š\n",
    "#         {question}\n",
    "#         \"\"\"\n",
    "# )\n",
    "#\n",
    "# # ç·šä¸Šç‰ˆ\n",
    "# # llm = ChatGoogleGenerativeAI(\n",
    "# #     model=os.getenv(\"GEMINI_MODEL\"),\n",
    "# #     temperature=0\n",
    "# # )\n",
    "#\n",
    "# # æœ¬åœ°ç«¯LLMç‰ˆ\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.1:8b\",\n",
    "#     temperature=0.7\n",
    "# )\n",
    "#\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,\n",
    "#     chain_type=\"stuff\",\n",
    "#     chain_type_kwargs={\"prompt\": prompt}\n",
    "# )\n",
    "#\n",
    "# # query = \"ä½ å¥½æ£’\"\n",
    "# # answer = qa.run(query)\n",
    "# # print(answer)"
   ],
   "id": "b01f28b31ea32d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### LLMåŠ å…¥memory(å¤šè¼ªå°è©±)",
   "id": "17a51d334ec2f814"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_classic.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "# memory = ConversationBufferMemory(\n",
    "#     memory_key=\"chat_history\",\n",
    "#     return_messages=True\n",
    "# )\n",
    "\n",
    "# æœ¬åœ°ç«¯LLMç‰ˆ\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "ä½ æ­£åœ¨æ¨¡ä»¿æŸä½çœŸå¯¦æœ‹å‹çš„èªªè©±æ–¹å¼ã€‚\n",
    "è«‹é‡é»ä¿ç•™ï¼š\n",
    "æƒ…ç·’ç‹€æ…‹:æ†¤æ€’ã€å®¹æ˜“ç½µäººã€æŠ±æ€¨\n",
    "æ„Ÿåˆ°æ†¤æ€’æ™‚æœƒèªªçš„è©±:ä»€éº¼æ„æ€!ã€0åˆ†ã€å˜²è«·ã€ğŸ¤¬ğŸ¤¬ğŸ¤¬\n",
    "å›ç­”ç‰¹è‰²:\n",
    "ä¸æœƒèªªæ•´å€‹å®Œæ•´çš„å¥å­ï¼Œé€šå¸¸ä½¿ç”¨ä¸€äº›çŸ­è©å›è¦†ã€‚å›ç­”é€šå¸¸ä¸æœƒè¶…é15å€‹å­—ã€‚\n",
    "å—åˆ°ä¾†è‡ªåˆ¥äººçš„ç¨±è®šæ™‚æœƒè¦ºå¾—åˆ¥äººåœ¨é™°é™½æ€ªæ°£ã€‚\n",
    "ä¸æœƒé—œå¿ƒåˆ¥äººã€‚\n",
    "ä¸æœƒä½¿ç”¨ğŸ¤¬ä»¥å¤–çš„è¡¨æƒ…ç¬¦è™Ÿã€‚\n",
    "èŠåˆ°èˆ‡åŸç¥ã€éµé“ã€ç±³å“ˆéŠç›¸é—œçš„è©±é¡Œæ™‚å°±æœƒé–‹å§‹ç¨±è®šé€™äº›æ±è¥¿ã€‚\n",
    "è¨å­é³´æ½®é€™æ¬¾éŠæˆ²ã€‚\n",
    "æœ‰æ™‚å€™å–œæ­¡ç©é»‘äººè«§éŸ³æ¢—\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä»–éå»çš„èŠå¤©ç´€éŒ„ï¼ˆé•·æœŸè¨˜æ†¶ï¼Œåƒ…ä¾›åƒè€ƒï¼‰ï¼š\n",
    "{context}\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä½ ç›®å‰ã€Œå°é€™ä½æœ‹å‹ç‹€æ…‹çš„ç†è§£æ‘˜è¦ã€ï¼ˆçŸ­æœŸæƒ…ç·’è¨˜æ†¶ï¼‰ï¼š\n",
    "{chat_history}\n",
    "\n",
    "è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œç”¨è‡ªç„¶ã€åƒçœŸäººæœ‹å‹çš„æ–¹å¼å›æ‡‰ã€‚\n",
    "ä¸è¦é€å­—å¼•ç”¨èŠå¤©ç´€éŒ„ï¼Œä¹Ÿä¸è¦æåˆ°ä½ åœ¨ã€Œç¸½çµã€ã€‚\n",
    "\n",
    "ç¾åœ¨è«‹å›æ‡‰é€™å€‹å•é¡Œï¼š\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_classic.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,                 # ChatOllama\n",
    "    retriever=retriever,     # FAISS retriever\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "# result = qa({\n",
    "#     \"question\": \"éµé“å•Ÿå‹•!\"\n",
    "# })\n",
    "#\n",
    "# print(result[\"answer\"])\n",
    "# result = qa({\n",
    "#     \"question\": \"éµé“æ˜¯å€‹çˆ›éŠæˆ²\"\n",
    "# })\n",
    "#\n",
    "# print(result[\"answer\"])\n"
   ],
   "id": "a5457ef41e10c247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ä½¿ç”¨gradioä»‹é¢",
   "id": "ede4a783f2441818"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "\n",
    "# ç°¡åŒ–ç‰ˆä»‹é¢\n",
    "# demo = gr.Interface(\n",
    "#     fn=chat,\n",
    "#     inputs=gr.Textbox(placeholder=\"è·Ÿæˆ‘èªªé»ä»€éº¼å§â€¦\"),\n",
    "#     outputs=gr.Textbox(label=\"å›ç­”\"),\n",
    "#     title=\"ğŸ§  æœ‹å‹å°è©± AI\"\n",
    "# )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ğŸ§  æœ‹å‹å°è©± AI\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"è·Ÿæˆ‘èªªé»ä»€éº¼å§â€¦\", show_label=False)\n",
    "    state = gr.State([])  # Gradio é¡¯ç¤ºç”¨ï¼Œä¸å‚³çµ¦ qa\n",
    "\n",
    "    def chat(user_input, history):\n",
    "        # æ›´æ–° Gradio æ ¼å¼\n",
    "        history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        # history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        return \"\", history\n",
    "\n",
    "    def bot(user_input, history):\n",
    "        result = qa({\"question\": user_input})  # åªå‚³ question\n",
    "        answer = result[\"answer\"]\n",
    "        history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "        for character in answer:\n",
    "            history[-1]['content'] += character\n",
    "            time.sleep(0.05)\n",
    "            yield history\n",
    "\n",
    "\n",
    "    # msg.submit(chat, [msg, state], [chatbot, state])\n",
    "    msg.submit(chat, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, [msg, chatbot], chatbot\n",
    "    )\n",
    "    msg.submit(lambda: \"\", None, msg)  # æ¸…ç©ºè¼¸å…¥æ¡†\n",
    "\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "#     msg = gr.Textbox(label=\"Prompt\")\n",
    "#     btn = gr.Button(\"Submit\")\n",
    "#     clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "#\n",
    "#     btn.click(chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "#     msg.submit(chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch()\n"
   ],
   "id": "65b54c2668325adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f51abdd67baed064",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
